# train ‚Äî Entra√Ænement des mod√®les de d√©tection DDoS

Ce r√©pertoire contient **la logique d‚Äôentra√Ænement des mod√®les de machine learning** √† partir des donn√©es pr√©trait√©es.

Objectifs :
- charger les donn√©es pr√©par√©es (`data/processed`)
- g√©rer le fort d√©s√©quilibre des classes
- entra√Æner plusieurs familles de mod√®les
- sauvegarder les mod√®les entra√Æn√©s
- permettre des exp√©rimentations contr√¥l√©es via configuration

---

## Structure du r√©pertoire

```
train/
‚îú‚îÄ‚îÄ __init__.py
‚îî‚îÄ‚îÄ train_models.py
```

---

## Vue d‚Äôensemble du workflow

1. Chargement de la configuration (`config/config_train.yaml`)
2. Chargement des donn√©es pr√©process√©es
3. Gestion du d√©s√©quilibre des classes
4. Construction des mod√®les selon la configuration
5. Entra√Ænement des mod√®les activ√©s
6. Sauvegarde des mod√®les entra√Æn√©s

---

## Donn√©es utilis√©es

Les donn√©es sont charg√©es depuis :

```
data/processed/
‚îú‚îÄ‚îÄ train_processed.csv
‚îî‚îÄ‚îÄ train_labels.csv
```

Caract√©ristiques :
- donn√©es d√©j√† nettoy√©es
- m√™mes transformations que celles utilis√©es en inf√©rence
- labels binaires :
  - `0` ‚Üí BENIGN
  - `1` ‚Üí DDoS

‚ö†Ô∏è **Aucune transformation de features n‚Äôest refaite ici**  
Tout le preprocessing est fig√© en amont.

---

## Gestion du d√©s√©quilibre des classes

Le script g√®re explicitement le **d√©s√©quilibre extr√™me** du dataset DDoS.

La strat√©gie est d√©finie dans le fichier de configuration.

### Strat√©gies support√©es

| Strat√©gie      | Description                         |
| -------------- | ----------------------------------- |
| `none`         | aucune correction                   |
| `class_weight` | pond√©ration automatique des classes |
| `oversample`   | sur-√©chantillonnage                 |
| `undersample`  | sous-√©chantillonnage                |
| `smote`        | SMOTE explicite                     |
| `hybrid`       | oversampling + undersampling        |

Les biblioth√®ques `imbalanced-learn` sont utilis√©es **si disponibles**, avec fallback gracieux.

---

### Pond√©ration automatique des classes

Lorsque `class_weight` est activ√© :
- calcul automatique via `compute_class_weight`
- adaptation sp√©cifique selon le mod√®le :
  - **XGBoost** ‚Üí `scale_pos_weight`
  - **LightGBM** ‚Üí `class_weight`
  - **CatBoost** ‚Üí `class_weights`
  - **Scikit-learn** ‚Üí `class_weight` standard

üëâ Cela permet une **gestion coh√©rente du d√©s√©quilibre**, quel que soit le framework.

---

## Mod√®les support√©s

Le script supporte plusieurs familles de mod√®les.

### Mod√®les classiques (scikit-learn)

- Decision Tree
- Random Forest
- Gradient Boosting
- AdaBoost
- Logistic Regression
- SVM
- Naive Bayes
- KNN

---

### Mod√®les boosting avanc√©s (optionnels)

- XGBoost
- LightGBM
- CatBoost

Ces mod√®les sont charg√©s **uniquement s‚Äôils sont install√©s**.  
Sinon, ils sont ignor√©s sans casser le pipeline.

---

## Configuration par fichier YAML

Le comportement du script est enti√®rement pilot√© par :

config/config_train.yaml

Il permet de d√©finir :
- les mod√®les activ√©s / d√©sactiv√©s
- les hyperparam√®tres de chaque mod√®le
- la strat√©gie de gestion du d√©s√©quilibre
- les ratios de sampling

üëâ Aucun param√®tre critique n‚Äôest cod√© en dur.

---

## Boucle d‚Äôentra√Ænement

Pour chaque mod√®le activ√© :

1. construction du mod√®le avec hyperparam√®tres
2. injection des poids de classes si n√©cessaire
3. entra√Ænement sur le dataset complet
4. mesure du temps d‚Äôentra√Ænement
5. sauvegarde du mod√®le

Les mod√®les sont sauvegard√©s dans :

```
models/
‚îú‚îÄ‚îÄ decision_tree.pkl
‚îú‚îÄ‚îÄ random_forest.pkl
‚îú‚îÄ‚îÄ xgboost.pkl
‚îî‚îÄ‚îÄ ...
```



---

## Bonnes pratiques appliqu√©es

- s√©paration claire preprocessing / entra√Ænement
- gestion robuste du d√©s√©quilibre
- fallback automatique si librairies absentes
- configuration centralis√©e
- sauvegarde syst√©matique des mod√®les
- reproductibilit√© des exp√©riences

---

## Quand utiliser ce dossier

- entra√Ænement initial des mod√®les
- comparaison de plusieurs algorithmes
- tuning d‚Äôhyperparam√®tres
- tests de strat√©gies de d√©s√©quilibre
- g√©n√©ration des mod√®les pour l‚Äôinf√©rence

---

## Perspectives d‚Äô√©volution

- cross-validation stratifi√©e
- early stopping pour les boosters
- suivi des exp√©riences (MLflow)
- s√©lection automatique du meilleur mod√®le
- entra√Ænement distribu√©

---

## R√©sum√©

Le dossier `train/` fournit un **pipeline d‚Äôentra√Ænement flexible, robuste et extensible**, capable de g√©rer :
- des datasets massifs
- un d√©s√©quilibre s√©v√®re
- plusieurs frameworks ML
- des contraintes r√©alistes de production