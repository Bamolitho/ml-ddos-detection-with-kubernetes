dataset:
  path: "../data/dataset.csv"
  sample_percent: 0.02        # pourcent du dataset utilisé pour le tuning
  random_seed: 42

output:
  model_dir: "../models/"
  report_dir: "./tuning_results/"
  dashboard_dir: "./dashboard/"

tuning:
  search_method: "halving"    # grid | random | halving
  cv: 3
  n_jobs: -1

# ------------------------------
# Liste des modèles activés
# Valeurs possibles : true | false
# ------------------------------
models:
  # Tree-Based Models
  decision_tree: false
  random_forest: false
  xgboost: true
  lightgbm: true
  catboost: false
  gradient_boosting: false
  adaboost: false
  
  # Linear Models
  logistic_regression: false
  svm: false

  # Simple Models
  naive_bayes: false
  knn: false

# ------------------------------
# Grilles d’hyperparamètres
# ------------------------------

grids:

  random_forest:
    n_estimators: [100, 200, 400]
    max_depth: [10, 20, 40]
    min_samples_split: [2, 5]

  xgboost:
    max_depth: [6, 10]
    learning_rate: [0.01, 0.1]
    n_estimators: [200, 400]

  lightgbm:
    num_leaves: [31, 63, 127]
    learning_rate: [0.01, 0.1]
    n_estimators: [200, 400]

  svm:
    C: [0.1, 1, 10]
    kernel: ["linear", "rbf"]

  logistic_regression:
    C: [0.1, 1.0, 10.0]

  knn:
    n_neighbors: [3, 5, 11]

  naive_bayes:
    var_smoothing: [1e-9, 1e-8, 1e-7]

  decision_tree:
    max_depth: [5, 10, 20]
    min_samples_split: [2, 5]

  gradient_boosting:
    learning_rate: [0.01, 0.1]
    n_estimators: [100, 200]

  adaboost:
    n_estimators: [50, 100, 200]
    learning_rate: [0.01, 0.1, 1.0]
